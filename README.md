# ğŸµ Controlador de MÃºsica por Gestos con Inteligencia Artificial

Este proyecto implementa un **asistente inteligente de escritorio** que permite controlar la reproducciÃ³n de mÃºsica mediante **gestos de la mano**, sin necesidad de utilizar teclas fÃ­sicas ni interfaces tÃ¡ctiles.

Utilizando tÃ©cnicas de **visiÃ³n por computadora** y un **modelo de clasificaciÃ³n entrenado con IA**, el sistema es capaz de reconocer gestos especÃ­ficos y traducirlos en acciones del sistema, como pausar una canciÃ³n, cambiar de pista o ajustar el volumen.

---

## ğŸ“Œ DescripciÃ³n del proyecto

Este asistente fue diseÃ±ado para mejorar la interacciÃ³n humano-computadora en entornos donde se desea controlar medios sin contacto fÃ­sico, como:

- ğŸ”Š **Escuchar mÃºsica mientras trabajas**
- ğŸ§ **Estudiar sin tocar el teclado**
- ğŸ’¡ **Casos de accesibilidad o discapacidad motriz leve**

El sistema utiliza:

- ğŸ“· **OpenCV** para la captura de video en tiempo real
- âœ‹ **MediaPipe Hands** para detectar 21 puntos clave de la mano
- ğŸ¤– **RandomForestClassifier** para clasificar los gestos
- âŒ¨ï¸ **PyAutoGUI y Pycaw** para simular teclas y ajustar volumen
- ğŸ’» **CustomTkinter** para ofrecer una interfaz grÃ¡fica moderna

---

## âš™ï¸ Funcionalidades principales

- Reconocimiento de los siguientes gestos:

| Gesto reconocido | AcciÃ³n del sistema |
|------------------|--------------------|
| `pause_play`     | â¯ï¸ Pausar/Reproducir mÃºsica |
| `volume_up`      | ğŸ”Š Subir volumen del sistema |
| `volume_down`    | ğŸ”‰ Bajar volumen del sistema |
| `next`           | â­ï¸ CanciÃ³n siguiente |
| `prev`           | â®ï¸ CanciÃ³n anterior |

- VisualizaciÃ³n en pantalla:
  - ğŸ§  Nombre del gesto detectado con emoji
  - ğŸ“Š Barra de confianza en tiempo real
  - âœ‹ VisualizaciÃ³n de puntos clave de la mano

- Interfaz grÃ¡fica inicial con botones para:
  - Iniciar el asistente
  - Leer instrucciones
  - Salir del programa

---

## ğŸ§  Â¿CÃ³mo funciona internamente?

1. El usuario inicia el sistema desde la interfaz grÃ¡fica (`launcher.py`)
2. La cÃ¡mara detecta la mano usando **MediaPipe**
3. Los puntos clave de la mano se procesan como vectores de entrada
4. El modelo IA (`RandomForest`) clasifica el gesto
5. Si la confianza es suficiente, se ejecuta la acciÃ³n correspondiente
6. El sistema muestra el resultado (emoji, nombre y barra de confianza)

---

## ğŸ–¥ï¸ Â¿CÃ³mo iniciar el programa?

Desde un entorno con Python instalado, ejecutar:

```bash
python launcher.py
